# Machine-learning with Python

This is a basic machine leaning program to create a model f(x) = ax + b or y = ax + b from datasets of y as a function of x.


## 1) Datasets

The datasets used is created thanks the make_regreassion function from the scikit-learn library.

## 2) Model

Then we create a random model. This is not a good model. There are a lots of errors. Our work is to find a model with a minimun of errors.

## 3) Cost Function

We create the cost function which calculates the errors of the model

## 4) Gradient ans gradient descent

We use the gradient descent method to minimize the errors

## 5) Action

Then we calculate the right model.

And this is it !

I did it for fun !



